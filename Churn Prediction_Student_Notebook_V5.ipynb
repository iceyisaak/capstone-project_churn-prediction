{"cells":[{"cell_type":"markdown","metadata":{"id":"Mg_ZAS0B2slE"},"source":["___\n","\n","<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n","\n","___"]},{"cell_type":"markdown","metadata":{"id":"8EjVhtzq2slH"},"source":["# WELCOME!"]},{"cell_type":"markdown","metadata":{"id":"JqV3cXW-2slL"},"source":["Welcome to \"***Employee Churn Analysis Project***\". This is the second project of Capstone Project Series, which you will be able to build your own classification models for a variety of business settings.\n","\n","Also you will research what is Employee Churn?, How it is different from customer churn, Exploratory data analysis and visualization of employee churn dataset using ***matplotlib*** and ***seaborn***, model building and evaluation using python ***scikit-learn*** and ***Tensorflow-Keras*** packages.\n","\n","You will be able to implement classification techniques in Python. Using Scikit-Learn allowing you to successfully make predictions with Distance Based, Bagging, Boosting algorithms for this project. On the other hand, for Deep Learning you will use Tensorflow-Keras.\n","\n","After taking Machine learning deployment course, you will able to deploy your model using *Streamlit*.\n","\n","Before diving into the project, please take a look at the determines and project structure.\n","\n","- NOTE: This project assumes that you already know the basics of coding in Python and are familiar with model deployement as well as the theory behind Distance Based, Bagging, Boosting algorithms, and Confusion Matrices. You can try more models and methods beside these to improve your model metrics.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4oRnVXpS2slN"},"source":["# #Determines\n","In this project you have HR data of a company. A study is requested from you to predict which employee will churn by using this data.\n","\n","The HR dataset has 14,999 samples. In the given dataset, you have two types of employee one who stayed and another who left the company.\n","\n","You can describe 10 attributes in detail as:\n","- ***satisfaction_level:*** It is employee satisfaction point, which ranges from 0-1.\n","- ***last_evaluation:*** It is evaluated performance by the employer, which also ranges from 0-1.\n","- ***number_projects:*** How many of projects assigned to an employee?\n","- ***average_monthly_hours:*** How many hours in averega an employee worked in a month?\n","- **time_spent_company:** time_spent_company means employee experience. The number of years spent by an employee in the company.\n","- ***work_accident:*** Whether an employee has had a work accident or not.\n","- ***promotion_last_5years:*** Whether an employee has had a promotion in the last 5 years or not.\n","- ***Departments:*** Employee's working department/division.\n","- ***Salary:*** Salary level of the employee such as low, medium and high.\n","- ***left:*** Whether the employee has left the company or not.\n","\n","First of all, to observe the structure of the data, outliers, missing values and features that affect the target variable, you must use exploratory data analysis and data visualization techniques.\n","\n","Then, you must perform data pre-processing operations such as ***Scaling*** and ***Encoding*** to increase the accuracy score of Gradient Descent Based or Distance-Based algorithms.\n","\n","You are asked to perform ***Cluster Analysis*** based on the information you obtain during exploratory data analysis and data visualization processes. The purpose of clustering analysis is to cluster data with similar characteristics.\n","\n","Once the data is ready to be applied to the model, you must ***split the data into train and test***. Then build a model to predict whether employees will churn or not. Train your models with your train set, test the success of your model with your test set.\n","\n","Try to make your predictions by using the ***Classification Algorithms***. You can use the related modules of the ***scikit-learn*** and ***Tensorflow-Keras*** library. You can use scikit-learn ***Classification Metrics*** module for accuracy calculation.\n","\n","Data drift and model drirft are key consepts about ML and MLOPS, you can monitor and check your data and models with plenty of ways and tools. ***Deepchecks*** is one of them and the leading tool for testing and for validating your machine learning models and data, and it enables doing so with minimal effort. In this project, you will apply ***Data Integrity, Train-Test Validation, and Model Evaluation*** checks.\n","Deepchecks Introduction : https://youtu.be/7ELdizoi6BU\n"]},{"cell_type":"markdown","metadata":{"id":"97xzRLNj2slO"},"source":["# #Tasks\n","\n","#### 1. Exploratory Data Analysis\n","- EDA is an initial process of analysis, in which you can summarize characteristics of data such as pattern, trends, outliers, and hypothesis testing using descriptive statistics and visualization.\n","- In the given dataset, you have two types of employee one who stayed and another who left the company. So, you can divide data into two groups and compare their characteristics.\n","\n","#### 2. Data Visualization\n","- Explore your data via visualizations to find-out:\n"," - What can be the reason of the churn?\n"," - Behavioral analysis of churns and not churns ..... etc.\n","\n","#### 3. Cluster Analysis\n","- Apply ***clustering algorithms*** and writedown your conclusions about the clusters you created.\n","\n","#### 5. Predictive Model Building\n","- Split Data as Train and Test set\n","- Built Classification Models(at least four models) and Evaluate Model Performances\n","\n","#### 6. Model Deployement\n","\n","- Save and Export the Best Model"]},{"cell_type":"markdown","metadata":{"id":"TyrWBiyM2sld"},"source":["## #Importing Modules and Predefined Functions#"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DVuK5K1XmEld"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"WLTGi7q02slP"},"source":["## 1. Exploratory Data Analysis"]},{"cell_type":"markdown","metadata":{},"source":["### 1.1. Apply Data Integrity Checks\n","* link: https://docs.deepchecks.com/stable/user-guide/tabular/auto_quickstarts/plot_quick_data_integrity.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Qd_Mxw-2sl9"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"0PsO9Iew2smG"},"source":["## 2. Data Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gt8FWYQu2smu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZeW1OpuHjFBG"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"c1Gp2f7q2snF"},"source":["## 3. Cluster Analysis\n","- Try to find hidden patterns in data with the help of unsupervised learning algorithms.\n","- Don't try to use clustering algoritms for classfication."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T0xg4NmCjSFt"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"WpmbaABr2snN"},"source":["## 4. Predictive Model Building"]},{"cell_type":"markdown","metadata":{},"source":["### 4.1. Train-Test Validation Checks\n","* link : https://docs.deepchecks.com/stable/user-guide/tabular/auto_quickstarts/plot_quick_train_test_validation.html"]},{"cell_type":"markdown","metadata":{"id":"pYsKmaZd2snO"},"source":["### 4.2. Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S15Bpefl2snS"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"z9P157eX2sn2"},"source":["### 4.3. Classification Algorithms\n"," - Try at least 4 ML/DL algorithms."]},{"cell_type":"markdown","metadata":{"id":"L8OkbOrC2snY"},"source":["#### 4.3.1. Model Building, Evaluating  and Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MefRCx542snY"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["##### 4.3.1.1 Apply Model Evaluation Checks***\n","* link : https://docs.deepchecks.com/stable/user-guide/tabular/auto_quickstarts/plot_quick_model_evaluation.html"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"VAiUMdtI2snk"},"source":["#### 4.3.2. Compare Models Performances\n","- Compare model performances according to metrics you choose for the problem."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CSUOz5302snx"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"90HfPd4w2sn1"},"source":["####  4.3.3 Prediction\n","- Make a demo prediction "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R0U41iE8QYJj"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Hv7E8XsazFMM"},"source":["## 5. Model Deployement\n","- Finalize your model with whole dataset and prepare for the deployment."]},{"cell_type":"markdown","metadata":{},"source":["### 5.1. Final Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"m5pwXBOkJPeM"},"source":["### 5.2. Save and Export the Best Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mmlin9CEzFr7"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"aD6JV41czCKr"},"source":["___\n","\n","<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n","\n","___"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"b91502e98c93ec413571a3c4a71c4e7e2f090119475bdef759aa0802c5125d05"}}},"nbformat":4,"nbformat_minor":0}
